# -*- coding: utf-8 -*-
"""Service disruptions based on logs and events.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mptkV-vR1tjDfeejY5Agn0CYg2tfhbjm

# **Service disruptions based on logs and events Prediction using Unsupervised Learning Techniques**

STEP 1 : Load dataset
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Load dataset
df = pd.read_csv("sys_failure.csv")

# Remove '%' and convert to numeric
for col in ["CPU_Usage", "Memory_Usage", "Disk_Usage"]:
    df[col] = df[col].str.rstrip('%').astype(float)

# Convert categorical columns to numerical values using Label Encoding
categorical_columns = ["Network_Usage", "Pod_Status", "K8s_Event_Log", "System_Log", "Network_Error"]
label_encoders = {}

for col in categorical_columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])  # Encode categorical values
    label_encoders[col] = le  # Store for later decoding

# Define target variable (Service Disruption)
df["Service_Disruption"] = df["System_Log"].apply(lambda x: 1 if x in ["Kubelet restart detected", "Disk Failure", "Timeout detected"] else 0)


# Drop unnecessary columns
X = df.drop(columns=["Service_Disruption", "Timestamp", "Node"])  # Features
y = df["Service_Disruption"]  # Target

df.drop(columns=["Timestamp","Node"], inplace=True)

"""STEP 2 : **Isolation Forest Implementation**"""

from sklearn.ensemble import IsolationForest


# Select feature columns (excluding Service_Disruption)
X = df.drop(columns=["Service_Disruption"])

# Train Isolation Forest
iso_forest = IsolationForest(contamination=0.02, random_state=42)  # Reduce to 2%
df["Anomaly_Score"] = iso_forest.fit_predict(X)
print(df["Anomaly_Score"].value_counts())  # See new distribution


# Convert to binary (1 = anomaly, 0 = normal)
df["Predicted_Service_Disruption"] = (df["Anomaly_Score"] == -1).astype(int)

"""**KMeans Clustering**"""

from sklearn.cluster import KMeans

# Select feature columns
X = df.drop(columns=["Service_Disruption"])

# Apply KMeans with 3 clusters (Normal & Disruptions)
kmeans = KMeans(n_clusters=3, random_state=42)
df["Cluster"] = kmeans.fit_predict(X)
print(df["Cluster"].value_counts())  # See new cluster sizes

"""STEP 3 : Compare both models"""

from sklearn.metrics import  roc_curve, auc
import seaborn as sns
import matplotlib.pyplot as plt

# Actual vs. Predicted Labels for Isolation Forest
y_true = df["Service_Disruption"]  # Actual disruptions
y_pred = df["Predicted_Service_Disruption"]  # Predictions from Isolation Forest
# ROC Curve
fpr, tpr, _ = roc_curve(y_true, y_pred)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6, 4))
plt.plot(fpr, tpr, color="blue", label="AUC = %0.2f" % roc_auc)
plt.plot([0, 1], [0, 1], color="red", linestyle="--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve (Isolation Forest)")
plt.legend()
plt.show()

import numpy as np

plt.figure(figsize=(8, 6))
sns.scatterplot(x=df["CPU_Usage"], y=df["Memory_Usage"], hue=df["Cluster"], palette="viridis")
plt.xlabel("CPU Usage")
plt.ylabel("Memory Usage")
plt.title("K-Means Clustering of Service Disruptions")
plt.legend(title="Cluster")
plt.show()

print("Average Resource Usage per Cluster:")
print(df.groupby("Cluster")[["CPU_Usage", "Memory_Usage", "Disk_Usage"]].mean())

"""STEP : 4 Heatmap Analysis"""

plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Feature Correlation Heatmap")
plt.show()